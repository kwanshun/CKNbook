import os
import logging
import google.generativeai as genai
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
try:
    from flask_limiter import Limiter
    from flask_limiter.util import get_remote_address
    LIMITER_AVAILABLE = True
except ImportError:
    LIMITER_AVAILABLE = False
    print("Warning: flask_limiter not available, rate limiting disabled")
from dotenv import load_dotenv
import re
from datetime import datetime

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('tone_toner.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Production configuration
app.config['ENV'] = 'production'
app.config['DEBUG'] = False
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'your-secret-key-change-this')

# CORS configuration - restrict in production
CORS(app, origins=os.getenv('ALLOWED_ORIGINS', '*').split(','))

# Rate limiting (if available)
if LIMITER_AVAILABLE:
    limiter = Limiter(
        key_func=get_remote_address,
        default_limits=["100 per hour", "10 per minute"]
    )
    limiter.init_app(app)
else:
    limiter = None

# Configure Gemini API
api_key = os.getenv('API_KEY')
if not api_key:
    logger.error("ERROR: API_KEY not found in environment variables")
    exit(1)

logger.info("Configuring Gemini API...")
genai.configure(api_key=api_key)

def load_system_prompt():
    """Load the system prompt from file"""
    try:
        with open('prompts/system_prompt.txt', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        logger.error("System prompt file not found")
        return "You are a helpful assistant that rewrites text."

def load_response_prompt():
    """Load the response prompt from file"""
    try:
        with open('prompts/response_prompt.txt', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        logger.error("Response prompt file not found")
        return "You are a helpful assistant that generates effective responses."

def validate_input(paragraph, tone, language):
    """Validate user input"""
    if not paragraph or len(paragraph.strip()) == 0:
        return False, "æ®µè½å…§å®¹ä¸èƒ½ç‚ºç©º"
    
    if len(paragraph) > 2000:
        return False, "æ®µè½å…§å®¹éé•·ï¼Œè«‹é™åˆ¶åœ¨2000å­—å…ƒä»¥å…§"
    
    valid_tones = ['æ´»æ½‘è¼•é¬†', 'æº«æš–', 'å°ˆæ¥­', 'è¬™è™›', 'å¹½é»˜']
    if tone not in valid_tones:
        return False, "ç„¡æ•ˆçš„èªèª¿é¸é …"
    
    valid_languages = ['å»£æ±è©±', 'æ™®é€šè©±', 'è‹±æ–‡', 'è¥¿ç­ç‰™æ–‡']
    if language not in valid_languages:
        return False, "ç„¡æ•ˆçš„èªè¨€é¸é …"
    
    # Basic content filtering - allow common punctuation and Chinese characters
    # Allow: word chars, whitespace, CJK chars, common punctuation including smart quotes
    if re.search(r'[^\w\s\u4e00-\u9fff\u3000-\u303f\uff00-\uffef\u2000-\u206f\u2010-\u2027\u2030-\u205f.,!?;:()""\'\-â€“â€”/\\&%@#*+<>=[\]{}|~`]', paragraph):
        return False, "åŒ…å«ä¸å…è¨±çš„å­—å…ƒ"
    
    return True, ""

def fine_tune_text(paragraph, tone, language):
    """Fine-tune the paragraph using Gemini API"""
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        system_prompt = load_system_prompt()
        user_prompt = f"""
        [Tone]: {tone}
        [Language or Dialect]: {language}
        
        åŸæ–‡æ®µè½:
        {paragraph}
        
        è«‹æ ¹æ“šä¸Šè¿°èªèª¿å’Œèªè¨€è¦æ±‚ï¼Œé‡å¯«é€™å€‹æ®µè½ç‚ºä¸‰å€‹ä¸åŒçš„é¸é …ã€‚
        """
        
        full_prompt = system_prompt + "\n\n" + user_prompt
        
        logger.info(f"Processing request - Tone: {tone}, Language: {language}")
        response = model.generate_content(full_prompt)
        
        if response.text:
            logger.info("Successfully generated response")
            return response.text
        else:
            logger.warning("Empty response from API")
            return "éŒ¯èª¤: API å›æ‡‰ç‚ºç©º"
        
    except Exception as e:
        logger.error(f"Error in fine_tune_text: {str(e)}")
        return f"éŒ¯èª¤: æœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"

def generate_effective_response(text, image_base64, tone):
    """Generate effective responses using Gemini API"""
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        response_prompt = load_response_prompt()
        
        # Find relevant knowledge content based on user input
        relevant_knowledge = find_relevant_knowledge(text)
        
        user_prompt = f"""
        ç”¨æˆ¶è¼¸å…¥ï¼š{text}
        èªèª¿è¦æ±‚ï¼š{tone}
        ç›¸é—œæ›¸æœ¬çŸ¥è­˜ï¼š{relevant_knowledge}
        """
        
        if image_base64:
            user_prompt += f"\n\nåœ–ç‰‡å·²ä¸Šå‚³ï¼Œè«‹åˆ†æåœ–ç‰‡å…§å®¹ä¸¦ç´å…¥å›æ‡‰è€ƒæ…®ã€‚"
        
        full_prompt = response_prompt + "\n\n" + user_prompt
        
        print(f"Generating effective response with tone: {tone}...")
        print(f"Relevant knowledge found: {len(relevant_knowledge)} characters")
        
        if image_base64:
            # Handle image analysis
            image_data = {"mime_type": "image/jpeg", "data": image_base64}
            response = model.generate_content([full_prompt, image_data])
        else:
            response = model.generate_content(full_prompt)
        
        print(f"Response generation: {response.text[:200]}...")
        
        if response.text:
            return response.text
        else:
            return "éŒ¯èª¤: API å›æ‡‰ç‚ºç©º"
        
    except Exception as e:
        print(f"Error in generate_effective_response: {str(e)}")
        return f"éŒ¯èª¤: {str(e)}"

def find_relevant_knowledge(user_input):
    """Find relevant knowledge content based on user input"""
    import glob
    import os
    import re
    
    # Keywords that might indicate specific topics
    keywords = {
        'ç¶­ç”Ÿç´ ': ['ç¶­ç”Ÿç´ ', 'vitamin', 'ç¶­ä»–å‘½'],
        'è›‹ç™½è³ª': ['è›‹ç™½è³ª', 'protein', 'æ°¨åŸºé…¸'],
        'è„‚è‚ª': ['è„‚è‚ª', 'fat', 'æ²¹', 'è†½å›ºé†‡'],
        'ç¢³æ°´åŒ–åˆç‰©': ['ç¢³æ°´åŒ–åˆç‰©', 'carb', 'ç³–', 'æ¾±ç²‰'],
        'ç¤¦ç‰©è³ª': ['ç¤¦ç‰©è³ª', 'mineral', 'éˆ£', 'éµ', 'é‹…'],
        'æ—©é¤': ['æ—©é¤', 'breakfast', 'æ—©ä¸Š'],
        'ç‡Ÿé¤Šè£œå……': ['ç‡Ÿé¤Šè£œå……', 'supplement', 'è£œå……åŠ‘'],
        'çƒ¹èª¿': ['çƒ¹èª¿', 'cooking', 'ç…®', 'è’¸', 'ç‚’'],
        'å¥åº·': ['å¥åº·', 'health', 'é¤Šç”Ÿ'],
        'ç–¾ç—…': ['ç–¾ç—…', 'disease', 'ç—…', 'ç—‡ç‹€']
    }
    
    # Find matching topics
    relevant_topics = []
    user_input_lower = user_input.lower()
    
    for topic, topic_keywords in keywords.items():
        for keyword in topic_keywords:
            if keyword.lower() in user_input_lower:
                relevant_topics.append(topic)
                break
    
    # If no specific topics found, use general knowledge
    if not relevant_topics:
        relevant_topics = ['general']
    
    # Load relevant chapter content
    relevant_content = []
    
    # Always include some general knowledge
    try:
        with open('book_knowledge.txt', 'r', encoding='utf-8') as f:
            general_knowledge = f.read()
            relevant_content.append(f"ä¸€èˆ¬ç‡Ÿé¤ŠçŸ¥è­˜ï¼š\n{general_knowledge}")
    except:
        pass
    
    # Load specific chapter content based on topics
    knowledge_files = glob.glob('knowledge/*.md')
    
    for file_path in knowledge_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # Check if this chapter is relevant to the user's input
                is_relevant = False
                for topic in relevant_topics:
                    if topic in content or any(keyword in content for keyword in keywords.get(topic, [])):
                        is_relevant = True
                        break
                
                if is_relevant:
                    # Extract chapter title and key content
                    lines = content.split('\n')
                    title = lines[0] if lines else "æœªçŸ¥ç« ç¯€"
                    # Get first few paragraphs for context
                    key_content = '\n'.join(lines[1:min(10, len(lines))])
                    relevant_content.append(f"{title}\n{key_content}")
                    
        except Exception as e:
            print(f"Error reading knowledge file {file_path}: {e}")
            continue
    
    # If no specific content found, try to find chapters that might be relevant
    if len(relevant_content) <= 1:  # Only general knowledge
        # Load a few random chapters to provide context
        import random
        knowledge_files = glob.glob('knowledge/*.md')
        if knowledge_files:
            selected_files = random.sample(knowledge_files, min(3, len(knowledge_files)))
            for file_path in selected_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = content.split('\n')
                        title = lines[0] if lines else "æœªçŸ¥ç« ç¯€"
                        key_content = '\n'.join(lines[1:min(8, len(lines))])
                        relevant_content.append(f"{title}\n{key_content}")
                except:
                    continue
    
    return "\n\n---\n\n".join(relevant_content)

def generate_encouragement(user_input):
    """Generate encouragement based on user input analysis"""
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        encouragement_prompt = """
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å­¸ç¿’ç¾¤çµ„ç®¡ç†å“¡ï¼Œå°ˆé–€åˆ†æå­¸å“¡åˆ†äº«çš„å…§å®¹ä¸¦æä¾›åˆé©çš„é¼“å‹µå›è¦†ã€‚

è«‹åˆ†æç”¨æˆ¶åˆ†äº«çš„å…§å®¹ï¼Œä¸¦æ ¹æ“šä»¥ä¸‹5ç¨®é¼“å‹µé¡å‹é¸æ“‡æœ€åˆé©çš„ä¸€ç¨®ï¼š

1. ğŸ‘ã€ç²¾è¯ç­†è¨˜ã€‘- é©åˆè©³ç›¡æ•´ç†ã€æ¢åˆ—æ¸…æ™°ã€é‡é»åˆ°ä½çš„åˆ†äº«
2. ğŸŒŸã€æ·±åº¦å­¸ç¿’ã€‘- é©åˆç”¨å¿ƒæç…‰æ›¸ä¸­ç²¾è¯+å€‹äººå¯¦è¸å¿ƒå¾—çš„åˆ†äº«  
3. ğŸ“šã€å„ªè³ªåˆ†äº«ã€‘- é©åˆçµæ§‹åŒ–ç­†è¨˜+é‡‘å¥æ¨™è¨»çš„èªçœŸåˆ†äº«
4. ğŸ’¡ã€çŸ¥è­˜ç‡ˆå¡”ã€‘- é©åˆå¾ç†è«–åˆ°æ¡ˆä¾‹è§£æéƒ½è¶…æ‰å¯¦çš„æ·±åº¦åˆ†äº«
5. ğŸ¯ã€å­¸ç¿’æ¥·æ¨¡ã€‘- é©åˆé™„æœ‰ã€Œè¡Œå‹•æ¸…å–®ã€ç­‰å¯¦ç”¨å…§å®¹çš„åˆ†äº«

é‡è¦ï¼šencouragement æ¬„ä½å¿…é ˆä½¿ç”¨å»£æ±è©±ï¼ˆç²µèªï¼‰è¡¨é”ï¼Œä¸èƒ½ä½¿ç”¨æ™®é€šè©±ã€‚

è«‹ä»¥JSONæ ¼å¼å›è¦†ï¼š
{
    "analysis": "å°åˆ†äº«å…§å®¹çš„ç°¡çŸ­åˆ†æï¼ˆ50å­—å…§ï¼‰",
    "type": "æ¨è–¦çš„é¼“å‹µé¡å‹ï¼ˆåŒ…å«emojiå’Œæ¨™é¡Œï¼‰",
    "encouragement1": "ç¬¬ä¸€å€‹é¼“å‹µå›è¦†é¸é …ï¼Œå¿…é ˆä½¿ç”¨å»£æ±è©±ï¼ˆç²µèªï¼‰è¡¨é”ï¼Œé™åˆ¶åœ¨30å­—ä»¥å…§",
    "encouragement2": "ç¬¬äºŒå€‹é¼“å‹µå›è¦†é¸é …ï¼Œå¿…é ˆä½¿ç”¨å»£æ±è©±ï¼ˆç²µèªï¼‰è¡¨é”ï¼Œé™åˆ¶åœ¨30å­—ä»¥å…§",
    "encouragement3": "ç¬¬ä¸‰å€‹é¼“å‹µå›è¦†é¸é …ï¼Œå¿…é ˆä½¿ç”¨å»£æ±è©±ï¼ˆç²µèªï¼‰è¡¨é”ï¼Œé™åˆ¶åœ¨30å­—ä»¥å…§"
}
"""
        
        user_prompt = f"""
å­¸å“¡åˆ†äº«å…§å®¹ï¼š
{user_input}

è«‹åˆ†æé€™å€‹åˆ†äº«å…§å®¹ï¼Œé¸æ“‡æœ€åˆé©çš„é¼“å‹µé¡å‹ï¼Œä¸¦ç”Ÿæˆ3å€‹ä¸åŒçš„é¼“å‹µå›è¦†é¸é …ã€‚
æ³¨æ„ï¼šæ‰€æœ‰encouragementé¸é …éƒ½å¿…é ˆä½¿ç”¨å»£æ±è©±ï¼ˆç²µèªï¼‰ä¾†è¡¨é”ï¼Œæ¯å€‹é¸é …éƒ½è¦æœ‰ä¸åŒçš„é¢¨æ ¼ï¼š
- é¸é …1ï¼šæº«é¦¨é¼“å‹µé¢¨æ ¼
- é¸é …2ï¼šæ´»æ½‘è®šç¾é¢¨æ ¼  
- é¸é …3ï¼šå¯¦ç”¨å»ºè­°é¢¨æ ¼

ä¾‹å¦‚ï¼š
- å¥½å»å•Šï¼å­¸ä»¥è‡´ç”¨ï¼ŒçœŸä¿‚å¥½æœ‰ç”¨ï¼
- çœŸä¿‚å¥½ç”¨å¿ƒï¼Œç¹¼çºŒåŠ æ²¹ï¼
- å¥½è©³ç´°å˜…åˆ†äº«ï¼Œå¤šè¬ä½ ï¼

ä¸è¦ä½¿ç”¨æ™®é€šè©±ã€‚
"""
        
        full_prompt = encouragement_prompt + "\n\n" + user_prompt
        
        logger.info(f"Generating encouragement for input length: {len(user_input)}")
        response = model.generate_content(full_prompt)
        
        if response.text:
            # Try to parse as JSON
            try:
                # Clean up the response text - remove markdown code blocks if present
                clean_text = response.text.strip()
                
                # Remove markdown code blocks more thoroughly
                if '```json' in clean_text:
                    # Extract content between ```json and ```
                    start = clean_text.find('```json') + 7
                    end = clean_text.rfind('```')
                    if end > start:
                        clean_text = clean_text[start:end].strip()
                elif clean_text.startswith('```') and clean_text.endswith('```'):
                    # Remove ``` at start and end
                    clean_text = clean_text[3:-3].strip()
                
                logger.info(f"Cleaned text for JSON parsing: {clean_text[:100]}...")
                
                import json
                response_data = json.loads(clean_text)
                logger.info("Successfully parsed JSON response")
                return response_data  # Return the actual JSON object, not a string
            except json.JSONDecodeError as e:
                logger.warning(f"JSON parsing failed: {e}")
                logger.info("Falling back to plain text response")
                return response.text
        else:
            logger.warning("Empty response from API")
            return "éŒ¯èª¤: API å›æ‡‰ç‚ºç©º"
        
    except Exception as e:
        logger.error(f"Error in generate_encouragement: {str(e)}")
        return f"éŒ¯èª¤: {str(e)}"

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/encouragement')
def encouragement():
    return render_template('encouragement.html')

@app.route('/quiz')
def quiz():
    return render_template('quiz.html')

@app.route('/effective-reply')
def effective_reply():
    return render_template('effective_reply.html')

@app.route('/process', methods=['POST'])
def process_text():
    try:
        if not request.is_json:
            return jsonify({'error': 'è«‹æ±‚æ ¼å¼éŒ¯èª¤'}), 400
            
        data = request.json
        paragraph = data.get('paragraph', '').strip()
        tone = data.get('tone', '')
        language = data.get('language', '')
        
        # Validate input
        is_valid, error_msg = validate_input(paragraph, tone, language)
        if not is_valid:
            logger.warning(f"Invalid input: {error_msg}")
            return jsonify({'error': error_msg}), 400
        
        # Log request (without sensitive data)
        logger.info(f"Processing request - Length: {len(paragraph)}, Tone: {tone}, Language: {language}")
        
        result = fine_tune_text(paragraph, tone, language)
        
        return jsonify({'result': result})
        
    except Exception as e:
        logger.error(f"Error in process_text: {str(e)}")
        return jsonify({'error': 'è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦'}), 500

@app.errorhandler(429)
def rate_limit_handler(e):
    return jsonify({'error': 'è«‹æ±‚éæ–¼é »ç¹ï¼Œè«‹ç¨å¾Œå†è©¦'}), 429

@app.errorhandler(404)
def not_found_handler(e):
    return jsonify({'error': 'é é¢ä¸å­˜åœ¨'}), 404

@app.route('/generate-encouragement', methods=['POST'])
def generate_encouragement_route():
    try:
        if not request.is_json:
            return jsonify({'error': 'è«‹æ±‚æ ¼å¼éŒ¯èª¤'}), 400
            
        data = request.json
        user_input = data.get('input', '').strip()
        
        if not user_input:
            return jsonify({'error': 'è«‹è¼¸å…¥å­¸å“¡åˆ†äº«çš„å…§å®¹'}), 400
        
        if len(user_input) > 2000:
            return jsonify({'error': 'è¼¸å…¥å…§å®¹éé•·ï¼Œè«‹é™åˆ¶åœ¨2000å­—å…ƒä»¥å…§'}), 400
        
        # Log request
        logger.info(f"Processing encouragement request - Length: {len(user_input)}")
        
        result = generate_encouragement(user_input)
        
        return jsonify({'result': result})
        
    except Exception as e:
        logger.error(f"Error in generate_encouragement_route: {str(e)}")
        return jsonify({'error': 'è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦'}), 500

@app.errorhandler(500)
def internal_error_handler(e):
    logger.error(f"Internal server error: {str(e)}")
    return jsonify({'error': 'æœå‹™å™¨å…§éƒ¨éŒ¯èª¤'}), 500

if __name__ == '__main__':
    # This should only be used for development
    # In production, use a proper WSGI server like Gunicorn
    port = int(os.getenv('PORT', 5001))
    app.run(host='0.0.0.0', port=port, debug=False)
